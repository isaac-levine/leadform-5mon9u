{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "title": "AI Response Time",
      "type": "gauge",
      "datasource": "Prometheus",
      "description": "Average AI processing time with thresholds at 300ms and 500ms",
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 0,
        "y": 0
      },
      "targets": [
        {
          "expr": "rate(ai_processing_time_seconds_sum[5m]) / rate(ai_processing_time_seconds_count[5m])",
          "legendFormat": "Average Response Time"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "green"
              },
              {
                "value": 0.3,
                "color": "yellow"
              },
              {
                "value": 0.5,
                "color": "red"
              }
            ]
          },
          "unit": "s",
          "decimals": 3,
          "min": 0,
          "max": 1
        }
      }
    },
    {
      "title": "AI Confidence Distribution",
      "type": "histogram",
      "datasource": "Prometheus",
      "description": "Distribution of AI confidence scores across all processed messages",
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 8,
        "y": 0
      },
      "targets": [
        {
          "expr": "ai_confidence_score_bucket",
          "legendFormat": "Confidence Distribution"
        }
      ],
      "options": {
        "bucketSize": 0.1,
        "bucketOffset": 0,
        "combine": false
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit",
          "min": 0,
          "max": 1
        }
      }
    },
    {
      "title": "Message Processing Rate",
      "type": "timeseries",
      "datasource": "Prometheus",
      "description": "Number of messages processed per second over time",
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 16,
        "y": 0
      },
      "targets": [
        {
          "expr": "rate(ai_messages_processed_total[5m])",
          "legendFormat": "Messages/sec"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "mps",
          "decimals": 2,
          "color": {
            "mode": "palette-classic"
          }
        }
      }
    },
    {
      "title": "Error Rate",
      "type": "timeseries",
      "datasource": "Prometheus",
      "description": "AI processing errors per second with error type breakdown",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "targets": [
        {
          "expr": "rate(ai_processing_errors_total[5m])",
          "legendFormat": "{{error_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "errors/s",
          "min": 0
        }
      }
    },
    {
      "title": "Memory Usage",
      "type": "gauge",
      "datasource": "Prometheus",
      "description": "Current AI service memory consumption",
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 12,
        "y": 8
      },
      "targets": [
        {
          "expr": "process_resident_memory_bytes{job=\"ai-service\"}",
          "legendFormat": "Memory Usage"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "bytes",
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "green"
              },
              {
                "value": 1073741824,
                "color": "yellow"
              },
              {
                "value": 2147483648,
                "color": "red"
              }
            ]
          }
        }
      }
    },
    {
      "title": "CPU Usage",
      "type": "timeseries",
      "datasource": "Prometheus",
      "description": "AI service CPU utilization over time",
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 18,
        "y": 8
      },
      "targets": [
        {
          "expr": "rate(process_cpu_seconds_total{job=\"ai-service\"}[5m])",
          "legendFormat": "CPU Usage"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit",
          "max": 1,
          "decimals": 2,
          "color": {
            "mode": "palette-classic"
          }
        }
      }
    }
  ],
  "refresh": "10s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": [
    "ai-service",
    "monitoring",
    "performance"
  ],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "Prometheus",
          "value": "Prometheus"
        },
        "hide": 0,
        "includeAll": false,
        "label": "datasource",
        "multi": false,
        "name": "DS_PROMETHEUS",
        "options": [],
        "query": "prometheus",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      }
    ]
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "AI Service Metrics",
  "uid": "ai-metrics",
  "version": 1,
  "weekStart": ""
}